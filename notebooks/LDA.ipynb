{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation (LDA)\n",
    "\n",
    "This notebook contains an example of training an LDA topic modeling applied to news articles from which we will try to model what kind of topic they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article\n",
       "0  In the Washington of 2016, even when the polic...\n",
       "1    Donald Trump has used Twitter  —   his prefe...\n",
       "2    Donald Trump is unabashedly praising Russian...\n",
       "3  Updated at 2:50 p. m. ET, Russian President Vl...\n",
       "4  From photography, illustration and video, to d..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "npr = pd.read_csv('../UPDATED_NLP_COURSE/05-Topic-Modeling/npr.csv')\n",
    "npr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the Washington of 2016, even when the policy can be bipartisan, the politics cannot. And in that sense, this year shows little sign of ending on Dec. 31. When President Obama moved to sanction Russia over its alleged interference in the U. S. election just concluded, some Republicans who had long called for similar or more severe measures could scarcely bring themselves to approve. House Speaker Paul Ryan called the Obama measures ”appropriate” but also ”overdue” and ”a prime example of this administration’s ineffective foreign policy that has left America weaker in the eyes of the world.” Other GOP leaders sounded much the same theme. ”[We have] been urging President Obama for years to take strong action to deter Russia’s worldwide aggression, including its   operations,” wrote Rep. Devin Nunes,  . chairman of the House Intelligence Committee. ”Now with just a few weeks left in office, the president has suddenly decided that some stronger measures are indeed warranted.” Appearing on CNN, frequent Obama critic Trent Franks,  . called for ”much tougher” actions and said three times that Obama had ”finally found his tongue.” Meanwhile, at    and on Fox News, various spokesmen for   Trump said Obama’s real target was not the Russians at all but the man poised to take over the White House in less than three weeks. They spoke of Obama trying to ”tie Trump’s hands” or ”box him in,” meaning the   would be forced either to keep the sanctions or be at odds with Republicans who want to be tougher still on Moscow. Throughout 2016, Trump has repeatedly called not for sanctions but for closer ties with Russia, including cooperation in the fight against ISIS. Russia has battled ISIS in Syria on behalf of that country’s embattled dictator, Bashar Assad, bombing the besieged   city of Aleppo that fell to Assad’s forces this week. During the campaign, Trump even urged Russia to ”find” missing emails from the private server of his opponent, Hillary Clinton. He has exchanged public encomiums with Russian President Vladimir Putin on several occasions and added his doubts about the current U. S. levels of support for NATO  —   Putin’s longtime nemesis. There have also been suggestions that Trump’s extensive business dealings with various Russians are the reason he refuses to release his tax returns. All those issues have been disquieting to some Republicans for many months. Sens. John McCain,  . and Lindsay Graham,  . C. prominent senior members of the Armed Services Committee, have accepted the assessment of 17 U. S. intelligence agencies regarding the role of Russia in the hacking of various Democratic committees last year. That includes the FBI and CIA consensus that the Russian goal was not just to discredit American democracy but to defeat Clinton and elect Trump. They say the great majority of their Senate colleagues agree with them, and McCain has slated an Armed Services hearing on cyberthreats for Jan. 5. But the politicizing of the Russian actions  —   the idea that they helped Trump win  —   has also made the issue difficult for Republican leaders. It has allowed Trump supporters to push back on the intelligence agencies and say the entire issue is designed to undermine Trump’s legitimacy. Senate Majority Leader Mitch McConnell has so far resisted calls for a select committee to look into the Russian interference in the 2016 campaign. He has said it is enough for Sen. Richard Burr,  . C. to look into it as chairman of the Senate Intelligence Committee. Typically, Republican leaders and spokesmen say there is no evidence that the actual voting or tallying on Nov. 8 was compromised, and that is true. But it is also a red herring, as interference in those functions has not been alleged and is not the focus of the U. S. intelligence agencies’ concern. For his part, Trump has shown little interest in delving into what happened. He has cast doubt on the U. S. intelligence reports to date and suggested ”no one really knows what happened.” He also has suggested that computers make it very difficult to know who is using them. This week, Trump said it was time to ”get on with our lives and do more important things.” However, at week’s end he did agree to have an intelligence briefing on the subject next week. The   has not wanted the daily intelligence briefings available to him in recent weeks, preferring that they be given to the men he has chosen as his vice president (Mike Pence) and national security adviser (Mike Flynn) with Trump taking them only occasionally. The irony of this controversy arising at the eleventh hour of the Obama presidency can scarcely be overstated, and it defines the dilemma facing both the outgoing president and the incoming party in control. Obama appears to have been reluctant to retaliate against the Russian hacking before the election for fear of seeming to interfere with the election himself. The Republicans, meanwhile, have for years called for greater confrontation with the Russians, with Obama usually resisting. Obama did join with NATO in punishing the Russians with economic sanctions over the annexation of Crimea. Those sanctions may have been painful, coming as they did alongside falling prices for oil  —   the commodity that keeps the Russian economy afloat. On other occasions, despite Russian provocations through surrogates in Syria and elsewhere, Obama did not make overt moves to force Russia’s hand. That includes occasions when Russia was believed to be hacking critical computer systems in neighboring Ukraine, Estonia and Poland. But this week, following a chorus of confirmation from the U. S. intelligence community regarding the Russian role in computer hacking in the political campaign, Obama acted. He imposed a set of mostly diplomatic actions such as sanctioning some Russian officials, closing two diplomatic compounds and expelling 35 Russian diplomats. There may have been more damaging measures taken covertly, and some Russophobes in Washington held out hope for that. But the visible portion of the program scarcely amounted to major retribution. And Putin saw fit to diminish the Obama sanctions further by declining to respond. Although his government has steadfastly denied any interference in the U. S. election, Putin rejected his own foreign minister’s recommended package of    responses. (He even sent an invitation for U. S. diplomats to send their children to a holiday party in Moscow.) That allowed Putin to appear for the moment to be ”the bigger man,” even as he spurned Obama and kept up what has looked like a public bromance with Trump, who tweeted: ”Great move on delay (by V. Putin)   I always knew he was very smart!” At the moment it may seem that the overall Russia question amounts to the first crisis facing the Trump presidency. Whether forced by this campaign interference issue or not, Trump must grasp the nettle of a relationship Mitt Romney once called the greatest threat to U. S. security in the world. To be sure, Trump needs to dispel doubts about his ability to stand up to Putin, who has bullied and cajoled his way to center stage in recent world affairs. But Trump also seems determined to turn the page on past U. S. commitments, from free trade philosophy to funding of NATO and the United Nations. And if his Twitter account is any guide, Trump shows little concern about the conundrum others perceive to be facing him. Above all, Trump has shown himself determined to play by his own rules. A year ago, many were confident that would not work for him in the world of presidential politics. We are about to find out whether it works for him in the Oval Office.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npr.Article[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the content above, we might think the article 0 is about politics.\n",
    "\n",
    "Now, let's create the document term matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11992x54777 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3033388 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# max_df=0.9 will discard words that appear in 90% of the documents\n",
    "# this is to get rid of commond words.\n",
    "# min_df=2 the minimum documents in which a word has to appear in order\n",
    "# to count it\n",
    "cv = CountVectorizer(max_df=0.9, min_df=2, stop_words='english')\n",
    "dtm = cv.fit_transform(npr.Article)\n",
    "dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the document term matrix we can now train the LDA model using this vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 34s, sys: 6.24 s, total: 8min 40s\n",
      "Wall time: 1min 27s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='batch', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_components=7, n_jobs=None, n_topics=None, perp_tol=0.1,\n",
       "             random_state=42, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# n_components is the number of topics I want to detect\n",
    "LDA = LatentDirichletAllocation(n_components=7, random_state=42)\n",
    "LDA.fit(dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to proceed to extract the interesting values to match them with the vocabulary to get an idea of what we got.\n",
    "\n",
    "### Step 1: Grab the vocabulary of words\n",
    "We can rely on the count vectorizer we trained before since this contains the reference for every single term we got from the Document Term Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 54777\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of words: {len(cv.get_feature_names())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the feature names is just a list of the words, each with an index that we can access to know what is the human readable word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word index 3806 is: asking\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def print_random_word():\n",
    "    fn = cv.get_feature_names()\n",
    "    random_word_id = random.randint(0, len(fn))\n",
    "    print(f\"Word index {random_word_id} is: {fn[random_word_id]}\")\n",
    "\n",
    "print_random_word()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 Grab the topics\n",
    "Now with the trained LDA we can just grab the obtained topics. Each topic will be associated with an N number of words, but we will get the index of such words, that's why we need the vocabulary from above.\n",
    "\n",
    "First, we can observe that the obtained components are the ones we specified at the moment of training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(LDA.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 54777)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA.components_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a numpy array of shape 7 (the number of topics), 54777 (each word in the vocabulary). For each word we have a probability of occurence for that particular topic.\n",
    "\n",
    "What we need to do now is to grab the highest probability words for the topics.\n",
    "\n",
    "#### Note:\n",
    "In a numpy array, we can call the `argsort()` method which will return another array with the indexes of the original array but sorted in terms of the original values from lowest to highest. This is perfect for our purpose since we need to get the highest probability words for each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of argsort()\n",
    "import numpy as np\n",
    "arr = np.array([10, 200, 1])\n",
    "# From this array we can observe that in terms of the index of each element,\n",
    "# from the lowest to the highest that would be: [2, 0, 1] because:\n",
    "# arr[2] = 1, arr[0]=10 and arr[1]=200\n",
    "arr.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33390, 36310, 21228, 10425, 31464,  8149, 36283, 22673, 42561,\n",
       "       42993])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_topic = LDA.components_[0]\n",
    "# we need the last ten because those are the ones with highest probability\n",
    "top_10_single_topic = single_topic.argsort()[-10:]\n",
    "top_10_single_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now simply map the indexes with the vocabulary we got earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the first topic, we got the following words:\n",
      "new\n",
      "percent\n",
      "government\n",
      "company\n",
      "million\n",
      "care\n",
      "people\n",
      "health\n",
      "said\n",
      "says\n"
     ]
    }
   ],
   "source": [
    "print(\"For the first topic, we got the following words:\")\n",
    "for index in top_10_single_topic:\n",
    "    print(cv.get_feature_names()[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it seems the first topic is about politics and healthcare.\n",
    "\n",
    "Now let's obtain the top 10 words for each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topic_words(top=10):\n",
    "    vocab = cv.get_feature_names()\n",
    "    for topic, lda in enumerate(LDA.components_):\n",
    "        top_n = lda.argsort()[-top:]\n",
    "        print(f\">>>For topic #{topic}, the top {top} words are:\")\n",
    "        words = [vocab[index] for index in top_n]\n",
    "        print(f\"{words}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>For topic #0, the top 15 words are:\n",
      "['companies', 'money', 'year', 'federal', '000', 'new', 'percent', 'government', 'company', 'million', 'care', 'people', 'health', 'said', 'says']\n",
      "\n",
      ">>>For topic #1, the top 15 words are:\n",
      "['military', 'house', 'security', 'russia', 'government', 'npr', 'reports', 'says', 'news', 'people', 'told', 'police', 'president', 'trump', 'said']\n",
      "\n",
      ">>>For topic #2, the top 15 words are:\n",
      "['way', 'world', 'family', 'home', 'day', 'time', 'water', 'city', 'new', 'years', 'food', 'just', 'people', 'like', 'says']\n",
      "\n",
      ">>>For topic #3, the top 15 words are:\n",
      "['time', 'new', 'don', 'years', 'medical', 'disease', 'patients', 'just', 'children', 'study', 'like', 'women', 'health', 'people', 'says']\n",
      "\n",
      ">>>For topic #4, the top 15 words are:\n",
      "['voters', 'vote', 'election', 'party', 'new', 'obama', 'court', 'republican', 'campaign', 'people', 'state', 'president', 'clinton', 'said', 'trump']\n",
      "\n",
      ">>>For topic #5, the top 15 words are:\n",
      "['years', 'going', 've', 'life', 'don', 'new', 'way', 'music', 'really', 'time', 'know', 'think', 'people', 'just', 'like']\n",
      "\n",
      ">>>For topic #6, the top 15 words are:\n",
      "['student', 'years', 'data', 'science', 'university', 'people', 'time', 'schools', 'just', 'education', 'new', 'like', 'students', 'school', 'says']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_topic_words(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's attach the obtained topics to the original documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.1 s, sys: 484 ms, total: 34.6 s\n",
      "Wall time: 5.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "topic_results = LDA.transform(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11992, 7)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_results.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we got is an array of shape 11992 (the total number of documents), 7 (total number of topics). But for each topic we have the probability of the document to belong to a particular topic. So for instance, let's take a look at the first document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02, 0.68, 0.  , 0.  , 0.3 , 0.  , 0.  ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_results[0].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This array is telling us that the document $0$ has a $68\\%$ probability of being topic #1, which from the description above is about:\n",
    "\n",
    "```\n",
    "['military', 'house', 'security', 'russia', 'government', 'npr', 'reports', 'says', 'news', 'people', 'told', 'police', 'president', 'trump', 'said']\n",
    "```\n",
    "Which seems to be closely related with politics, and indeed it was our assumption before training the LDA model!\n",
    "\n",
    "Now, let's apply the logic to the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr['Topic'] = topic_results.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I did not want to join yoga class. I hated tho...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>With a   who has publicly supported the debunk...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I was standing by the airport exit, debating w...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>If movies were trying to be more realistic, pe...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Eighteen years ago, on New Year’s Eve, David F...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>For years now, some of the best, wildest, most...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>For years now, some of the best, wildest, most...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The Colorado River is like a giant bank accoun...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>For the last installment of NPR’s holiday reci...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Being overweight can raise your blood pressure...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Who’s the YouTube star of 2016? Adele singing ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Here’s a quick roundup of some of the   you ma...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ben Johnston doesn’t follow the rules of music...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>David Bowie, Prince and George Michael are all...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>In November, the typically straitlaced Office ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Article  Topic\n",
       "0   In the Washington of 2016, even when the polic...      1\n",
       "1     Donald Trump has used Twitter  —   his prefe...      1\n",
       "2     Donald Trump is unabashedly praising Russian...      1\n",
       "3   Updated at 2:50 p. m. ET, Russian President Vl...      1\n",
       "4   From photography, illustration and video, to d...      2\n",
       "5   I did not want to join yoga class. I hated tho...      3\n",
       "6   With a   who has publicly supported the debunk...      3\n",
       "7   I was standing by the airport exit, debating w...      2\n",
       "8   If movies were trying to be more realistic, pe...      3\n",
       "9   Eighteen years ago, on New Year’s Eve, David F...      2\n",
       "10  For years now, some of the best, wildest, most...      5\n",
       "11  For years now, some of the best, wildest, most...      5\n",
       "12  The Colorado River is like a giant bank accoun...      2\n",
       "13  For the last installment of NPR’s holiday reci...      2\n",
       "14  Being overweight can raise your blood pressure...      3\n",
       "15  Who’s the YouTube star of 2016? Adele singing ...      5\n",
       "16  Here’s a quick roundup of some of the   you ma...      2\n",
       "17  Ben Johnston doesn’t follow the rules of music...      5\n",
       "18  David Bowie, Prince and George Michael are all...      5\n",
       "19  In November, the typically straitlaced Office ...      1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npr.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we have nicely assigned topics to each document!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
