{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA Bot\n",
    "\n",
    "In this notebook we have an implementation of the ChatBot using the End to End memory networks implementation.\n",
    "\n",
    "First, let's load the data.\n",
    "\n",
    "### References\n",
    "* End-to-End Memory Networks paper: https://arxiv.org/abs/1503.08895"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy\n",
    "\n",
    "with open('../../datasets/train_qa.txt', 'rb') as file:\n",
    "    train_data = pickle.load(file)\n",
    "    \n",
    "with open('../../datasets/test_qa.txt', 'rb') as file:\n",
    "    test_data = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data count: 10000\n",
      "Test data count: 1000\n"
     ]
    }
   ],
   "source": [
    "train_count = len(train_data)\n",
    "test_count = len(test_data)\n",
    "print(f\"Train data count: {train_count}\")\n",
    "print(f\"Test data count: {test_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look at the kind of data we can find in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def print_record(data, index=None):\n",
    "    if not index:\n",
    "        index = random.randint(0, len(data) - 1)\n",
    "    record = data[index]\n",
    "    story = \" \".join(record[0])\n",
    "    story = [s.strip() for s in story.split(\".\")]\n",
    "    story = \"\\n\".join(story)\n",
    "    question = \" \".join(record[1])\n",
    "    answer = record[2]\n",
    "    print(f\"Story:\\n{story}\")\n",
    "    print(f\"Question: {question}\\n\")\n",
    "    print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story:\n",
      "Sandra went back to the hallway\n",
      "John moved to the bathroom\n",
      "Sandra journeyed to the kitchen\n",
      "John journeyed to the office\n",
      "\n",
      "Question: Is John in the garden ?\n",
      "\n",
      "Answer: no\n"
     ]
    }
   ],
   "source": [
    "print_record(train_data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story:\n",
      "Sandra went back to the bedroom\n",
      "Sandra went back to the garden\n",
      "Sandra went back to the kitchen\n",
      "John travelled to the kitchen\n",
      "\n",
      "Question: Is Sandra in the kitchen ?\n",
      "\n",
      "Answer: yes\n"
     ]
    }
   ],
   "source": [
    "print_record(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to ensure both the train and test data are used to create a vocabulary, this is to ensure the dictionary contains the elements used in both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = train_data + test_data\n",
    "\n",
    "# find all distinct elements between all the words\n",
    "vocab = set()\n",
    "for story, question, answer in all_data:\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))\n",
    "    \n",
    "vocab.add(\"yes\")\n",
    "vocab.add(\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len = len(vocab) + 1\n",
    "vocab_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the longest story and question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_story_len = [len(data[0]) for data in all_data]\n",
    "max_story_len = max(all_story_len)\n",
    "all_question_len = [len(data[1]) for data in all_data]\n",
    "max_question_len = max(all_question_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's vectorize the data.\n",
    "\n",
    "We need to fit a tokenizer with the vocabulary we just built to have a word index so we can feed it into the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'grabbed',\n",
       " 2: 'office',\n",
       " 3: 'got',\n",
       " 4: 'is',\n",
       " 5: 'moved',\n",
       " 6: 'back',\n",
       " 7: 'left',\n",
       " 8: 'dropped',\n",
       " 9: 'picked',\n",
       " 10: 'discarded',\n",
       " 11: 'bedroom',\n",
       " 12: 'there',\n",
       " 13: 'to',\n",
       " 14: '.',\n",
       " 15: 'daniel',\n",
       " 16: 'journeyed',\n",
       " 17: 'garden',\n",
       " 18: 'yes',\n",
       " 19: 'the',\n",
       " 20: 'travelled',\n",
       " 21: 'no',\n",
       " 22: 'put',\n",
       " 23: 'in',\n",
       " 24: 'apple',\n",
       " 25: 'sandra',\n",
       " 26: 'up',\n",
       " 27: 'kitchen',\n",
       " 28: 'went',\n",
       " 29: 'hallway',\n",
       " 30: 'bathroom',\n",
       " 31: '?',\n",
       " 32: 'football',\n",
       " 33: 'john',\n",
       " 34: 'took',\n",
       " 35: 'down',\n",
       " 36: 'mary',\n",
       " 37: 'milk'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)\n",
    "tokenizer.index_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just adding up all the texts grouped by type so we can later vectorize them, i.e., convert them into matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []\n",
    "\n",
    "for story, question, answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)\n",
    "    train_answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize stories\n",
    "This is a very important function, what this is doing is converting the human readable texts for each type (story, questions and answers) into their corresponding vector representations using the tokenizer we just trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_stories(data, word_index, max_story_length, max_question_length):\n",
    "    \"\"\"Vectorize stories.\n",
    "    \n",
    "    @param data: story, question and answer packed together\n",
    "    @param word_index: a pre-trained tokenizer word index\n",
    "    @param max_story_length: max story length characters to pad story sequences\n",
    "    @param max_question_length: max question length characters to pad question seq.\n",
    "    \"\"\"\n",
    "    # stories\n",
    "    X = []\n",
    "    # questions\n",
    "    Xq = []\n",
    "    # answers\n",
    "    Y = []\n",
    "    # every record in 'data' corresponds to a story, question and an answer\n",
    "    # that we need to vectorize to contruct the input data to feed the NN.\n",
    "    for story, question, answer in data:\n",
    "        # indices for every word in the story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        # indices for every word in the question\n",
    "        xq = [word_index[word.lower()] for word in question]\n",
    "        \n",
    "        # initialize the target matrix with the length of the word index\n",
    "        # plus one for keras pad sequence\n",
    "        y = np.zeros(len(word_index) + 1)\n",
    "        # only ligth up the element corresponding to the answer.\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "    # finally pad the sequences accordingly so stories and questions have the same\n",
    "    # lenght.\n",
    "    return (pad_sequences(X, maxlen=max_story_length), pad_sequences(Xq, maxlen=max_question_length), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train, queries_train, answerts_train = vectorize_stories(train_data, tokenizer.word_index, max_story_len, max_question_len)\n",
    "input_test, queries_test, answerts_test = vectorize_stories(test_data, tokenizer.word_index, max_story_len, max_question_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's observe how the data looks, we should obtain matrices where each row corresponds to a single record of story-question-answer. For the first two matrices, each column corresponds to the vocabulary word with the index value. And for the last one, each column corresponds to the index of the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 19, 11, 14],\n",
       "       [ 0,  0,  0, ..., 19, 29, 14],\n",
       "       [ 0,  0,  0, ..., 19, 30, 14],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 19, 11, 14],\n",
       "       [ 0,  0,  0, ..., 37, 12, 14],\n",
       "       [ 0,  0,  0, ..., 24, 12, 14]], dtype=int32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take a look at the answers, we should observe arrays with zeros, except for the index positions of the words 'yes' and 'no' which corresponds to the tokenizer word index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answerts_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we sum up the answerts test array, we will obtain the amount of yes/no answers and the column index position corresponds to the word index value for that word, i.e., 'yes' has index 18, then if we count the columns indices in the answers_test array, we will find the amount of yes indices, i.e., 497."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 497.,   0.,   0., 503.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answerts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 38)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answerts_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, Input, Activation, Dense, Permute, Dropout, add, dot, concatenate, LSTM\n",
    "\n",
    "input_seq = Input((max_story_len,))\n",
    "question = Input((max_question_len,))\n",
    "\n",
    "vocab_size = len(vocab) + 1\n",
    "\n",
    "# Input encoder M (for stories)\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size, output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "# this will output a tensor of shape (samples, story_max_len, embedding_dim)\n",
    "\n",
    "# Input encoder C\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size, output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "# this will output a tensor of shape (samples, story_max_len, max_question_len)\n",
    "\n",
    "# Questions encoder\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size, output_dim=64, input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "# this will output a tensor of shape (samples, query_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice here we are using the functional API of Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_4:0' shape=(?, 6) dtype=float32>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_encoded_m = input_encoder_m(input_seq)\n",
    "input_encoded_c = input_encoder_c(input_seq)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, according to the paper we need to compute a match $u^T \\cdot m_i$ where:\n",
    "* $u^T$ is the result of embedding the queries with similar dimensions as the story to obtain an internal state $u$\n",
    "* $m_i$ is the encoded (embedded) matrix of stories or sentences we want to store in memory.\n",
    "\n",
    "We later need to pass this to a softmax function to compute the match:\n",
    "$$\n",
    "p_i=Softmax(u^T \\cdot m_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to calculate the response vector from the memory $o$ which is a sum (add) over the transformed inputs $c_i$ weighted by the probability vector from the input.\n",
    "$$\n",
    "o=\\sum_{i} p_ic_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = add([match, input_encoded_c])\n",
    "response = Permute((2, 1))(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can concatenate the response with the question encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_2/concat:0' shape=(?, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And pass this into a LSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       multiple             2432        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_6 (Sequential)       (None, 6, 64)        2432        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 156, 6)       0           sequential_4[1][0]               \n",
      "                                                                 sequential_6[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 156, 6)       0           dot_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_5 (Sequential)       multiple             228         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 156, 6)       0           activation_3[0][0]               \n",
      "                                                                 sequential_5[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_2 (Permute)             (None, 6, 156)       0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 6, 220)       0           permute_2[0][0]                  \n",
      "                                                                 sequential_6[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 32)           32384       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32)           0           lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 38)           1254        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 38)           0           dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "answer = LSTM(32)(answer)\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer) # (samples, vocab_size) # YES/NO\n",
    "answer = Activation('softmax')(answer)\n",
    "\n",
    "# Then build the final model\n",
    "model = Model([input_seq, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
