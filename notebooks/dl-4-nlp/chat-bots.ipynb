{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat bots with python\n",
    "\n",
    "This notebook contains a Keras implementation of the paper entitled: [End-To-End Memory Networks](https://arxiv.org/pdf/1503.08895.pdf) by Sainbayar Sukhbaatar et al. The idea is to train a Q&A chat bot by training an ANN using a data set of contexts for questions and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open('../../datasets/train_qa.txt', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "    \n",
    "with open('../../datasets/test_qa.txt', 'rb') as f:\n",
    "    test_data = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 10000\n",
      "Train examples:\n",
      " [(['Mary', 'moved', 'to', 'the', 'bathroom', '.', 'Sandra', 'journeyed', 'to', 'the', 'bedroom', '.'], ['Is', 'Sandra', 'in', 'the', 'hallway', '?'], 'no'), (['Mary', 'moved', 'to', 'the', 'bathroom', '.', 'Sandra', 'journeyed', 'to', 'the', 'bedroom', '.', 'Mary', 'went', 'back', 'to', 'the', 'bedroom', '.', 'Daniel', 'went', 'back', 'to', 'the', 'hallway', '.'], ['Is', 'Daniel', 'in', 'the', 'bathroom', '?'], 'no')]\n"
     ]
    }
   ],
   "source": [
    "train_size = len(train_data)\n",
    "print(f\"Train size: {train_size}\")\n",
    "print(f\"Train examples:\\n {train_data[:2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input data corresponds to short stories (the context), followed by a question about the context, and finally the answer to that particular question. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The context: ['Mary', 'moved', 'to', 'the', 'bathroom', '.', 'Sandra', 'journeyed', 'to', 'the', 'bedroom', '.']\n",
      "The question: ['Is', 'Sandra', 'in', 'the', 'hallway', '?']\n",
      "The answer: no\n"
     ]
    }
   ],
   "source": [
    "context = train_data[0][0]\n",
    "question = train_data[0][1]\n",
    "answer = train_data[0][2]\n",
    "print(f\"The context: {context}\")\n",
    "print(f\"The question: {question}\")\n",
    "print(f\"The answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's construct a vocabulary from the data we have. Basically, we need to gather all the unique words from the three types of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = train_data + test_data\n",
    "vocab = set()\n",
    "for context, question, answer in all_data:\n",
    "    vocab = vocab.union(set(context))\n",
    "    vocab = vocab.union(set(question))\n",
    "    vocab = vocab.union({answer})\n",
    "vocab_len = len(vocab) + 1 # Necessary for keras given how it pad sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the longest story/context, question and answers. This is important when defining the matrices that will be passed to keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_lenghts = [len(data[0]) for data in all_data]\n",
    "max_story_len = max(story_lenghts)\n",
    "\n",
    "question_lenghts = [len(data[1]) for data in all_data]\n",
    "max_question_len = max(question_lenghts)\n",
    "\n",
    "answer_lenghts = [len(data[2]) for data in all_data]\n",
    "max_answer_len = max(answer_lenghts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max story lenght: 156\n",
      "Max question lenght: 6\n",
      "Max answer lenght: 3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Max story lenght: {max_story_len}\")\n",
    "print(f\"Max question lenght: {max_question_len}\")\n",
    "print(f\"Max answer lenght: {max_answer_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mary': 1,\n",
       " 'milk': 2,\n",
       " 'is': 3,\n",
       " 'the': 4,\n",
       " 'went': 5,\n",
       " 'kitchen': 6,\n",
       " '.': 7,\n",
       " 'daniel': 8,\n",
       " 'journeyed': 9,\n",
       " 'no': 10,\n",
       " 'grabbed': 11,\n",
       " 'john': 12,\n",
       " 'garden': 13,\n",
       " 'discarded': 14,\n",
       " 'sandra': 15,\n",
       " 'got': 16,\n",
       " 'travelled': 17,\n",
       " 'yes': 18,\n",
       " 'bathroom': 19,\n",
       " 'hallway': 20,\n",
       " 'put': 21,\n",
       " 'bedroom': 22,\n",
       " 'took': 23,\n",
       " 'moved': 24,\n",
       " 'football': 25,\n",
       " 'to': 26,\n",
       " 'picked': 27,\n",
       " 'office': 28,\n",
       " 'dropped': 29,\n",
       " 'in': 30,\n",
       " 'apple': 31,\n",
       " 'left': 32,\n",
       " '?': 33,\n",
       " 'down': 34,\n",
       " 'there': 35,\n",
       " 'up': 36,\n",
       " 'back': 37}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can prepare the training data using the trained tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answer_text = []\n",
    "\n",
    "for story, question, answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)\n",
    "    train_answer_text.append(answer)\n",
    "    \n",
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)\n",
    "train_question_seq = tokenizer.texts_to_sequences(train_question_text)\n",
    "train_answer_seq = tokenizer.texts_to_sequences(train_answer_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_stories(data, word_index, max_story_len, max_question_len):\n",
    "    X = []\n",
    "    Xq = []\n",
    "    Y = []\n",
    "    for story, question, answer in data:\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        xq = [word_index[word.lower()] for word in question]\n",
    "        y = np.zeros(len(word_index) + 1)\n",
    "        y[word_index[answer]] = 1\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "    return pad_sequences(X, maxlen=max_story_len), pad_sequences(Xq, maxlen=max_question_len), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, questions_train, answers_train = vectorize_stories(train_data, \n",
    "                                                                 tokenizer.word_index, \n",
    "                                                                 max_story_len, \n",
    "                                                                 max_question_len)\n",
    "\n",
    "inputs_test, questions_test, answers_test = vectorize_stories(test_data, \n",
    "                                                                 tokenizer.word_index, \n",
    "                                                                 max_story_len, \n",
    "                                                                 max_question_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 156)\n",
      "(10000, 6)\n",
      "(10000, 38)\n"
     ]
    }
   ],
   "source": [
    "print(inputs_train.shape)\n",
    "print(questions_train.shape)\n",
    "print(answers_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout, add, dot, concatenate, LSTM\n",
    "\n",
    "# Input of the stories, placeholder shape=(max_story_len, batch_size)\n",
    "input_sequence = Input(shape=(max_story_len,))\n",
    "question = Input(shape=(max_question_len,))\n",
    "\n",
    "# vocab_len\n",
    "vocab_size = len(vocab) + 1\n",
    "\n",
    "# Input encoder M\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size, output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "# Output: (samples, story_maxlen, embedding_dim)\n",
    "\n",
    "# Input encoder C\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size, output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "# Output: (samples, story_maxlen, max_question_len)\n",
    "\n",
    "# Question encoder\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size, output_dim=64, input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "# Output: (samples, embedding_dim)\n",
    "\n",
    "#######\n",
    "# Encoder(Input) ----> Encoder, this is the result of the encoder\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)\n",
    "\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)\n",
    "\n",
    "response = add([match, input_encoded_c])\n",
    "response = Permute((2, 1))(response)\n",
    "\n",
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'sequential_12/dropout_14/cond/Identity:0' shape=(None, 6, 64) dtype=float32>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_4/concat:0' shape=(None, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_8:0' shape=(None, 6) dtype=float32>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_10 (Sequential)      multiple             2432        input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_12 (Sequential)      (None, 6, 64)        2432        input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_4 (Dot)                     (None, 156, 6)       0           sequential_10[1][0]              \n",
      "                                                                 sequential_12[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 156, 6)       0           dot_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_11 (Sequential)      multiple             228         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 156, 6)       0           activation_6[0][0]               \n",
      "                                                                 sequential_11[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "permute_4 (Permute)             (None, 6, 156)       0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 6, 220)       0           permute_4[0][0]                  \n",
      "                                                                 sequential_12[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   (None, 32)           32384       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 32)           0           lstm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 38)           1254        dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 38)           0           dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "answer = LSTM(32)(answer)\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer) # (samples, vocab_size) # Yes/ No\n",
    "answer = Activation(\"softmax\")(answer)\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'activation_7/Softmax:0' shape=(None, 38) dtype=float32>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 16, 4, 2, 35, 7, 12, 24, 26, 4, 22, 7])], dtype=object)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 2s 184us/step - loss: 0.6937 - accuracy: 0.5042 - val_loss: 0.6937 - val_accuracy: 0.4750\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 2s 180us/step - loss: 0.6929 - accuracy: 0.5083 - val_loss: 0.6940 - val_accuracy: 0.4860\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 2s 184us/step - loss: 0.6858 - accuracy: 0.5319 - val_loss: 0.6903 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 2s 183us/step - loss: 0.6693 - accuracy: 0.5763 - val_loss: 0.6497 - val_accuracy: 0.6380\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 2s 183us/step - loss: 0.6232 - accuracy: 0.6660 - val_loss: 0.5904 - val_accuracy: 0.7150\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 2s 182us/step - loss: 0.5818 - accuracy: 0.7009 - val_loss: 0.5662 - val_accuracy: 0.7180\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 2s 183us/step - loss: 0.5471 - accuracy: 0.7320 - val_loss: 0.5232 - val_accuracy: 0.7540\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 2s 186us/step - loss: 0.5200 - accuracy: 0.7566 - val_loss: 0.4824 - val_accuracy: 0.7870\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 2s 186us/step - loss: 0.4902 - accuracy: 0.7794 - val_loss: 0.4635 - val_accuracy: 0.7910\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 2s 182us/step - loss: 0.4670 - accuracy: 0.7956 - val_loss: 0.4389 - val_accuracy: 0.8030\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 2s 184us/step - loss: 0.4463 - accuracy: 0.8074 - val_loss: 0.4292 - val_accuracy: 0.8200\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 2s 183us/step - loss: 0.4285 - accuracy: 0.8217 - val_loss: 0.4181 - val_accuracy: 0.8230\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 2s 182us/step - loss: 0.4057 - accuracy: 0.8266 - val_loss: 0.4138 - val_accuracy: 0.8230\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 2s 181us/step - loss: 0.3979 - accuracy: 0.8339 - val_loss: 0.4016 - val_accuracy: 0.8280\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 2s 182us/step - loss: 0.3801 - accuracy: 0.8442 - val_loss: 0.4029 - val_accuracy: 0.8210\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 2s 180us/step - loss: 0.3786 - accuracy: 0.8421 - val_loss: 0.4012 - val_accuracy: 0.8210\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 2s 185us/step - loss: 0.3757 - accuracy: 0.8442 - val_loss: 0.4047 - val_accuracy: 0.8310\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 2s 186us/step - loss: 0.3679 - accuracy: 0.8442 - val_loss: 0.3888 - val_accuracy: 0.8270\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 2s 184us/step - loss: 0.3556 - accuracy: 0.8483 - val_loss: 0.4025 - val_accuracy: 0.8240\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 2s 183us/step - loss: 0.3529 - accuracy: 0.8480 - val_loss: 0.3985 - val_accuracy: 0.8260\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 2s 181us/step - loss: 0.3522 - accuracy: 0.8487 - val_loss: 0.3809 - val_accuracy: 0.8200\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 2s 186us/step - loss: 0.3456 - accuracy: 0.8522 - val_loss: 0.4081 - val_accuracy: 0.8220\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 2s 183us/step - loss: 0.3422 - accuracy: 0.8527 - val_loss: 0.3856 - val_accuracy: 0.8200\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 2s 184us/step - loss: 0.3362 - accuracy: 0.8560 - val_loss: 0.3821 - val_accuracy: 0.8270\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 2s 190us/step - loss: 0.3290 - accuracy: 0.8610 - val_loss: 0.3777 - val_accuracy: 0.8260\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 2s 185us/step - loss: 0.3314 - accuracy: 0.8590 - val_loss: 0.3796 - val_accuracy: 0.8300\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 2s 182us/step - loss: 0.3243 - accuracy: 0.8612 - val_loss: 0.3845 - val_accuracy: 0.8210\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 2s 184us/step - loss: 0.3179 - accuracy: 0.8618 - val_loss: 0.3700 - val_accuracy: 0.8360\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 2s 182us/step - loss: 0.3170 - accuracy: 0.8642 - val_loss: 0.3679 - val_accuracy: 0.8310\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 2s 183us/step - loss: 0.3133 - accuracy: 0.8673 - val_loss: 0.3546 - val_accuracy: 0.8340\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 2s 184us/step - loss: 0.3140 - accuracy: 0.8620 - val_loss: 0.3612 - val_accuracy: 0.8400\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 2s 182us/step - loss: 0.3079 - accuracy: 0.8662 - val_loss: 0.3641 - val_accuracy: 0.8400\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 2s 182us/step - loss: 0.3033 - accuracy: 0.8690 - val_loss: 0.3568 - val_accuracy: 0.8310\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 2s 183us/step - loss: 0.3033 - accuracy: 0.8720 - val_loss: 0.3552 - val_accuracy: 0.8320\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 2s 184us/step - loss: 0.3003 - accuracy: 0.8678 - val_loss: 0.3777 - val_accuracy: 0.8360\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 2s 180us/step - loss: 0.3013 - accuracy: 0.8681 - val_loss: 0.3630 - val_accuracy: 0.8300\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 2s 181us/step - loss: 0.3009 - accuracy: 0.8683 - val_loss: 0.3641 - val_accuracy: 0.8360\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 2s 177us/step - loss: 0.2955 - accuracy: 0.8726 - val_loss: 0.3686 - val_accuracy: 0.8360\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 2s 184us/step - loss: 0.2894 - accuracy: 0.8759 - val_loss: 0.3767 - val_accuracy: 0.8390\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 2s 185us/step - loss: 0.2936 - accuracy: 0.8712 - val_loss: 0.3752 - val_accuracy: 0.8340\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 2s 183us/step - loss: 0.2914 - accuracy: 0.8726 - val_loss: 0.3606 - val_accuracy: 0.8320\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 2s 182us/step - loss: 0.2880 - accuracy: 0.8743 - val_loss: 0.3656 - val_accuracy: 0.8390\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 2s 179us/step - loss: 0.2848 - accuracy: 0.8743 - val_loss: 0.3819 - val_accuracy: 0.8380\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 2s 180us/step - loss: 0.2842 - accuracy: 0.8763 - val_loss: 0.3727 - val_accuracy: 0.8290\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 2s 181us/step - loss: 0.2861 - accuracy: 0.8760 - val_loss: 0.3631 - val_accuracy: 0.8360\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 2s 181us/step - loss: 0.2867 - accuracy: 0.8754 - val_loss: 0.3794 - val_accuracy: 0.8410\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 2s 182us/step - loss: 0.2792 - accuracy: 0.8783 - val_loss: 0.3737 - val_accuracy: 0.8380\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 2s 180us/step - loss: 0.2753 - accuracy: 0.8808 - val_loss: 0.3891 - val_accuracy: 0.8330\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 2s 181us/step - loss: 0.2798 - accuracy: 0.8782 - val_loss: 0.3826 - val_accuracy: 0.8280\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 2s 183us/step - loss: 0.2812 - accuracy: 0.8789 - val_loss: 0.3761 - val_accuracy: 0.8330\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 2s 180us/step - loss: 0.2750 - accuracy: 0.8827 - val_loss: 0.3621 - val_accuracy: 0.8400\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 2s 182us/step - loss: 0.2730 - accuracy: 0.8802 - val_loss: 0.3784 - val_accuracy: 0.8340\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 2s 181us/step - loss: 0.2727 - accuracy: 0.8828 - val_loss: 0.4080 - val_accuracy: 0.8290\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 2s 182us/step - loss: 0.2675 - accuracy: 0.8841 - val_loss: 0.3775 - val_accuracy: 0.8310\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 179us/step - loss: 0.2710 - accuracy: 0.8831 - val_loss: 0.3829 - val_accuracy: 0.8360\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 2s 176us/step - loss: 0.2647 - accuracy: 0.8863 - val_loss: 0.3869 - val_accuracy: 0.8350\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 2s 178us/step - loss: 0.2694 - accuracy: 0.8835 - val_loss: 0.3826 - val_accuracy: 0.8350\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 2s 178us/step - loss: 0.2646 - accuracy: 0.8842 - val_loss: 0.3852 - val_accuracy: 0.8370\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 2s 178us/step - loss: 0.2644 - accuracy: 0.8846 - val_loss: 0.3811 - val_accuracy: 0.8370\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 2s 183us/step - loss: 0.2622 - accuracy: 0.8848 - val_loss: 0.4007 - val_accuracy: 0.8350\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 2s 178us/step - loss: 0.2630 - accuracy: 0.8861 - val_loss: 0.3897 - val_accuracy: 0.8380\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 2s 180us/step - loss: 0.2622 - accuracy: 0.8884 - val_loss: 0.3860 - val_accuracy: 0.8300\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 2s 178us/step - loss: 0.2632 - accuracy: 0.8898 - val_loss: 0.3884 - val_accuracy: 0.8320\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 2s 179us/step - loss: 0.2637 - accuracy: 0.8882 - val_loss: 0.3989 - val_accuracy: 0.8360\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 2s 171us/step - loss: 0.2602 - accuracy: 0.8878 - val_loss: 0.3993 - val_accuracy: 0.8360\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 2s 179us/step - loss: 0.2622 - accuracy: 0.8893 - val_loss: 0.4140 - val_accuracy: 0.8240\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 2s 178us/step - loss: 0.2532 - accuracy: 0.8891 - val_loss: 0.4057 - val_accuracy: 0.8260\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 2s 191us/step - loss: 0.2508 - accuracy: 0.8903 - val_loss: 0.4098 - val_accuracy: 0.8340\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 2s 197us/step - loss: 0.2535 - accuracy: 0.8904 - val_loss: 0.4006 - val_accuracy: 0.8250\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 2s 197us/step - loss: 0.2533 - accuracy: 0.8920 - val_loss: 0.3879 - val_accuracy: 0.8280\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 2s 189us/step - loss: 0.2495 - accuracy: 0.8944 - val_loss: 0.4164 - val_accuracy: 0.8300\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 2s 194us/step - loss: 0.2472 - accuracy: 0.8926 - val_loss: 0.4226 - val_accuracy: 0.8420\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 2s 192us/step - loss: 0.2436 - accuracy: 0.8961 - val_loss: 0.4190 - val_accuracy: 0.8360\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 2s 185us/step - loss: 0.2451 - accuracy: 0.8946 - val_loss: 0.4106 - val_accuracy: 0.8350\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 2s 184us/step - loss: 0.2455 - accuracy: 0.8958 - val_loss: 0.4311 - val_accuracy: 0.8300\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 2s 182us/step - loss: 0.2431 - accuracy: 0.8951 - val_loss: 0.3986 - val_accuracy: 0.8310\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 2s 181us/step - loss: 0.2387 - accuracy: 0.8973 - val_loss: 0.4378 - val_accuracy: 0.8250\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 2s 177us/step - loss: 0.2417 - accuracy: 0.8972 - val_loss: 0.4232 - val_accuracy: 0.8240\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 2s 180us/step - loss: 0.2388 - accuracy: 0.8967 - val_loss: 0.4210 - val_accuracy: 0.8260\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 2s 182us/step - loss: 0.2350 - accuracy: 0.9004 - val_loss: 0.4501 - val_accuracy: 0.8300\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 2s 181us/step - loss: 0.2363 - accuracy: 0.8974 - val_loss: 0.4090 - val_accuracy: 0.8340\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 2s 185us/step - loss: 0.2339 - accuracy: 0.9011 - val_loss: 0.4864 - val_accuracy: 0.8320\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 2s 187us/step - loss: 0.2361 - accuracy: 0.8977 - val_loss: 0.4529 - val_accuracy: 0.8310\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 2s 192us/step - loss: 0.2282 - accuracy: 0.9014 - val_loss: 0.4450 - val_accuracy: 0.8320\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 2s 182us/step - loss: 0.2290 - accuracy: 0.9023 - val_loss: 0.4616 - val_accuracy: 0.8270\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 2s 181us/step - loss: 0.2264 - accuracy: 0.9035 - val_loss: 0.4409 - val_accuracy: 0.8290\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 2s 181us/step - loss: 0.2268 - accuracy: 0.9056 - val_loss: 0.4680 - val_accuracy: 0.8290\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 2s 180us/step - loss: 0.2254 - accuracy: 0.9043 - val_loss: 0.4248 - val_accuracy: 0.8300\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 2s 181us/step - loss: 0.2287 - accuracy: 0.9028 - val_loss: 0.4369 - val_accuracy: 0.8290\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 2s 180us/step - loss: 0.2251 - accuracy: 0.9044 - val_loss: 0.4704 - val_accuracy: 0.8280\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 2s 180us/step - loss: 0.2206 - accuracy: 0.9073 - val_loss: 0.4672 - val_accuracy: 0.8280\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 2s 180us/step - loss: 0.2192 - accuracy: 0.9045 - val_loss: 0.4695 - val_accuracy: 0.8320\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 2s 184us/step - loss: 0.2236 - accuracy: 0.9071 - val_loss: 0.4515 - val_accuracy: 0.8310\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 2s 182us/step - loss: 0.2206 - accuracy: 0.9084 - val_loss: 0.4495 - val_accuracy: 0.8250\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 2s 180us/step - loss: 0.2152 - accuracy: 0.9092 - val_loss: 0.4577 - val_accuracy: 0.8300\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 2s 183us/step - loss: 0.2130 - accuracy: 0.9103 - val_loss: 0.4612 - val_accuracy: 0.8290\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 2s 184us/step - loss: 0.2204 - accuracy: 0.9083 - val_loss: 0.4986 - val_accuracy: 0.8270\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 2s 179us/step - loss: 0.2144 - accuracy: 0.9121 - val_loss: 0.4721 - val_accuracy: 0.8370\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 2s 183us/step - loss: 0.2153 - accuracy: 0.9089 - val_loss: 0.4598 - val_accuracy: 0.8300\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 2s 183us/step - loss: 0.2090 - accuracy: 0.9116 - val_loss: 0.4690 - val_accuracy: 0.8260\n",
      "CPU times: user 4min 41s, sys: 18.4 s, total: 4min 59s\n",
      "Wall time: 3min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit([inputs_train, questions_train], \n",
    "                    answers_train, \n",
    "                    batch_size=32, \n",
    "                    epochs=100, \n",
    "                    validation_data=([inputs_test, questions_test], answers_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([inputs_test, questions_test]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manualy validate some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'got',\n",
       " 'the',\n",
       " 'milk',\n",
       " 'there',\n",
       " '.',\n",
       " 'John',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'John', 'in', 'the', 'kitchen', '?']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_max = np.argmax(pred_results[0])\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems to be working!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99998367"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results[0][val_max]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is 99% sure the answer is no.\n",
    "\n",
    "### Create a new story to play with\n",
    "We only are allowed to use words within the vocabulary we trained the model as these are the only words it knows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story = \"Sandra left the office . Daniel went to the kitchen\"\n",
    "my_question = \"Is Daniel in the office ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['Sandra',\n",
       "   'left',\n",
       "   'the',\n",
       "   'office',\n",
       "   '.',\n",
       "   'Daniel',\n",
       "   'went',\n",
       "   'to',\n",
       "   'the',\n",
       "   'kitchen'],\n",
       "  ['Is', 'Daniel', 'in', 'the', 'office', '?'],\n",
       "  'yes')]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data = [(my_story.split(), my_question.split(), 'yes')]\n",
    "my_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story, my_question, my_answer = vectorize_stories(my_data, tokenizer.word_index, max_story_len, max_question_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results = model.predict([my_story, my_question])\n",
    "val_max = np.argmax(pred_results[0])\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
