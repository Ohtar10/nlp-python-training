{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Basics with Spacy\n",
    "This notebook contains basics of NLP with Spacy\n",
    "\n",
    "## Create nlp object with a specific language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# load the simplified version of the english core language\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a simple document\n",
    "This document will be automatically parsed and processed with spacy with the defined language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Tesla is looking at buying U.S. startup for $6 million')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From there we can take a look at the elements of the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token               POS                 S-dep               \n",
      "Tesla               PROPN               nsubj\n",
      "is                  VERB                aux\n",
      "looking             VERB                ROOT\n",
      "at                  ADP                 prep\n",
      "buying              VERB                pcomp\n",
      "U.S.                PROPN               compound\n",
      "startup             NOUN                dobj\n",
      "for                 ADP                 prep\n",
      "$                   SYM                 quantmod\n",
      "6                   NUM                 compound\n",
      "million             NUM                 pobj\n"
     ]
    }
   ],
   "source": [
    "col1 = \"Token\"\n",
    "col2 = \"POS\" # Part of Speech\n",
    "col3 = \"S-dep\" # Syntactic dependency\n",
    "\n",
    "print(f\"{col1:{20}}{col2:{20}}{col3:{20}}\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text:{20}}{token.pos_:{20}}{token.dep_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy pipeline object\n",
    "The core unit of Spacy is the pipeline object which is a processing/transformation pipeline that takes the original text and applies all the NLP transformations required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.Tagger at 0x7f0ca22bbd50>),\n",
       " ('parser', <spacy.pipeline.DependencyParser at 0x7f0ca1e4b770>),\n",
       " ('ner', <spacy.pipeline.EntityRecognizer at 0x7f0ca1e4bd10>)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe here, the default instantiation is a pipeline composed of three components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A parsed document is an iterable and the items can be accessed by index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 0th token in the document is: Tesla\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "print(f\"The {n}th token in the document is: {doc[n]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the different parsed elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens.doc import Doc\n",
    "import pandas as pd\n",
    "\n",
    "def get_doc_elements(doc: Doc):\n",
    "    elements = [\"text\", \"lemma\", \"pos\", \"tag\", \"shape\", \"alpha\", \"stop\"]\n",
    "    rows = [ [token.text, token.lemma_, token.pos_, token.tag_, token.shape_, token.is_alpha, token.is_stop] \n",
    "            for token in  doc]\n",
    "    return pd.DataFrame(rows, columns=elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>tag</th>\n",
       "      <th>shape</th>\n",
       "      <th>alpha</th>\n",
       "      <th>stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tesla</td>\n",
       "      <td>tesla</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Xxxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>be</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>looking</td>\n",
       "      <td>look</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBG</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>at</td>\n",
       "      <td>at</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>buying</td>\n",
       "      <td>buy</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBG</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>U.S.</td>\n",
       "      <td>u.s.</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>X.X.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>startup</td>\n",
       "      <td>startup</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "      <td>ADP</td>\n",
       "      <td>IN</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>$</td>\n",
       "      <td>$</td>\n",
       "      <td>SYM</td>\n",
       "      <td>$</td>\n",
       "      <td>$</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>d</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>million</td>\n",
       "      <td>million</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text    lemma    pos  tag  shape  alpha   stop\n",
       "0     Tesla    tesla  PROPN  NNP  Xxxxx   True  False\n",
       "1        is       be   VERB  VBZ     xx   True   True\n",
       "2   looking     look   VERB  VBG   xxxx   True  False\n",
       "3        at       at    ADP   IN     xx   True   True\n",
       "4    buying      buy   VERB  VBG   xxxx   True  False\n",
       "5      U.S.     u.s.  PROPN  NNP   X.X.  False  False\n",
       "6   startup  startup   NOUN   NN   xxxx   True  False\n",
       "7       for      for    ADP   IN    xxx   True   True\n",
       "8         $        $    SYM    $      $  False  False\n",
       "9         6        6    NUM   CD      d  False  False\n",
       "10  million  million    NUM   CD   xxxx   True  False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_elements = get_doc_elements(doc)\n",
    "doc_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where:\n",
    "\n",
    "|Tag|Description|doc2[0].tag|\n",
    "|:------|:------:|:------|\n",
    "|`.text`|The original word text<!-- .element: style=\"text-align:left;\" -->|`Tesla`|\n",
    "|`.lemma_`|The base form of the word|`tesla`|\n",
    "|`.pos_`|The simple part-of-speech tag|`PROPN`/`proper noun`|\n",
    "|`.tag_`|The detailed part-of-speech tag|`NNP`/`noun, proper singular`|\n",
    "|`.shape_`|The word shape â€“ capitalization, punctuation, digits|`Xxxxx`|\n",
    "|`.is_alpha`|Is the token an alpha character?|`True`|\n",
    "|`.is_stop`|Is the token part of a stop list, i.e. the most common words of the language?|`False`|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Span objects\n",
    "A span can be thought as a slice of a document, i.e., it can start from some index to another. This facilitates processing chunks of text instead of the whole corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definition of NLP according to Wikipedia \n",
    "doc = nlp(u\"Natural language processing (NLP) is a subfield of computer science, \\\n",
    "information engineering, and artificial intelligence concerned with the \\\n",
    "interactions between computers and human (natural) languages, in particular \\\n",
    "how to program computers to process and analyze large amounts of natural language data.\\\n",
    "Challenges in natural language processing frequently involve speech recognition, natural \\\n",
    "language understanding, and natural language generation.\")\n",
    "\n",
    "quote = doc[10:30]\n",
    "quote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice here that the slice is for tokens and not individual characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work with sentences\n",
    "We can iterate over a document sentences, i,e., phrases separated by period \".\" characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is the second sentence.\n",
      "And this is the last sentence.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"This is the first sentence. This is the second sentence. And this is the last sentence.\")\n",
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Each period is considered a token, so the second \"This\" in the above document is at index `6` not index `5`, index `5` is the previous period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token 5: .\n",
      "Token 6: This\n",
      "Is token 6 a sentence start? True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Token 5: {doc[5]}\")\n",
    "print(f\"Token 6: {doc[6]}\")\n",
    "print(f\"Is token 6 a sentence start? {doc[6].is_sent_start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
